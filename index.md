---
layout: default
title: 3D Object Detection Hub
permalink: /
---

# ðŸŽ‰ Welcome to the **3D Object Detection Hub**

This site was born out of a **Masterâ€™s thesis** effort to centralize and compare **every major 3D-OD method** using multiple sensor modalities. While many prior surveys focus on one sensor or era of work, here youâ€™ll find:

> **A unified, searchable, and maintainable catalog**  
> covering camera-only, LiDAR-only, and multi-modal fusion approaches - all organized by **sensor** and **representation**.

If you use this site or data, please cite our publication:

> Valverde, M., Moutinho, A., & Zacchi, J. V. (2025). [*A Survey of Deep Learning-Based 3D Object Detection Methods for Autonomous Driving Across Different Sensor Modalities.*](https://www.mdpi.com/1424-8220/25/17/5264) Sensors.

---

## ðŸ”— Navigate

- ðŸ“Š [**Datasets**](/datasets/)  
  A concise table of the leading benchmarks (KITTI, nuScenes, Waymo, â€¦) and their key properties.

- ðŸ› ï¸ [**Models**](/3d-object-detection/)  
  A comprehensive database of published 3D-OD methods.  
  â€¢ **Filter** by sensor â†’ representation  
  â€¢ **Search** for a method by name  
  â€¢ **Sort** by year, mAP, runtime, etc.

- ðŸ“š [**References**](/references/)  
  The full bibliography of every paper, library, and dataset used to create this work.

- ðŸ‘¤ [**About**](/about/)  
  Background on the site, the underlying thesis, and contact details.

---

## ðŸ“– Why This Hub?

Although 3D object detection has exploded over the last decade, existing resources often:

- âœ”ï¸ Cover only **one modality** (e.g. camera-only or LiDAR-only).  
- âœ”ï¸ Become **outdated** as new methods appear.  
- âœ”ï¸ Lack a **unified taxonomy** across sensors & representations.

**This Hub** aggregates:

1. **Multi-sensor methods** (monocular, stereo, multiview, point-cloud, voxels, fusionâ€¦).  
2. **Performance comparisons** across KITTI, nuScenes & Waymo.  
3. **Runtime metrics** to inform real-world feasibility.  
4. **Interactive filtering**, searching, and sorting.

---

## ðŸš€ What Youâ€™ll Find

### ðŸ“š Datasets & Benchmarks
- **KITTI** â€“ The foundational benchmark (2 cameras + 1 LiDAR) with 15 000 annotated frames.  
- **nuScenes** â€“ Multi-modal data from 6 cameras, 1 LiDAR, 5 radars over 1 000 scenes.  
- **Waymo Open** â€“ High-density 5 Ã— LiDAR + 5 Ã— camera over 1 150 segments and 230 000+ frames.  
â€¦and more (ApolloScape, Argoverse, Lyft Level 5, H3D).

### ðŸ› ï¸ Methods & Models
- **Monocular** (Mono3D, SMOKE, DD3D, MonoFlex, â€¦)  
- **Stereo & Multiview** (LIGA-Stereo, Pseudo-BEV, â€¦)  
- **LiDAR-only** (PointPillars, PV-RCNN, SECOND, â€¦)  
- **Multi-Modal Fusion** (MVXNet, CLOCS, FUTR3D, â€¦)  

Each entry shows **accuracy**, **inference time**, **paper link**, and **code availability**.

---

## ðŸ” How to Use

1. **Browse** the [Datasets](/datasets/) page to choose your benchmark.  
2. **Visit** [Models](/3d-object-detection/) to filter by sensor & representation.  
3. **Search** or **sort** by **mAP**, **runtime**, **year**, or **code availability**.  
4. **Click â€œLinkâ€** to read the original paperâ€”code links when available.  
5. **Cite** via the [References](/references/) section when you publish your own results! ðŸ“‘

---

## ðŸ™‹â€â™‚ï¸ About & Contact

For background on the thesis, site construction, and to reach out, visit ðŸ‘‰ [About](/about/) or drop me a line at âœ‰ï¸ [miguel.heitor.valverde@tecnico.ulisboa.pt](mailto:miguel.heitor.valverde@tecnico.ulisboa.pt).

---

> **Keep Exploring!**  
> Whether youâ€™re benchmarking a new sensor, prototyping a fusion network, or writing the next SOTA paper, the **3D Object Detection Hub** is here to accelerate your research. ðŸ”¬ðŸš—

---

## ðŸ”® Future Work

- ðŸ”„ Continuously update with **new methods** & **datasets**.  
- âš™ï¸ Introduce a **Sensor Guide**: strengths & trade-offs of cameras, LiDARs, radars.  
- ðŸ“Š Expand to **2D OD** and **Depth Estimation** surveys.  
- ðŸ“ Include references for a paper to be published, detailing how this study was carried out and its methodology.
 
## ðŸ“‘ Citation

If you use this site or data, please cite our publication:

> Valverde, M., Moutinho, A., & Zacchi, J. V. (2025). [*A Survey of Deep Learning-Based 3D Object Detection Methods for Autonomous Driving Across Different Sensor Modalities.*](https://www.mdpi.com/1424-8220/25/17/5264) Sensors.



