<!DOCTYPE html>
<html lang="en">
<!-- _includes/head.html -->
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>3D Object Detection Hub | 3D Object Detection Hub</title>
  <meta name="description" content="">

  
  

  <!-- favicon -->
  <link rel="icon" href="/favicon.ico" type="image/x-icon">

  <!-- custom dark-mode & layout overrides -->
  <link rel="stylesheet" href="/assets/styles.css">

  <!-- DataTables CSS -->
  <link
    rel="stylesheet"
    href="https://cdn.datatables.net/1.13.6/css/jquery.dataTables.min.css" />

  <!-- your overrides -->
  <link
    rel="stylesheet"
    href="/assets/datatables-overrides.css" />

  <!-- PapaParse, jQuery & DataTables JS -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/PapaParse/5.4.1/papaparse.min.js"></script>
  <script src="https://code.jquery.com/jquery-3.6.0.min.js"></script>
  <script
    src="https://cdn.datatables.net/1.13.6/js/jquery.dataTables.min.js"></script>
    
</head>

<body>
  <header class="site-header">
    <div class="site-content">
      <h1 class="site-title">
        <a href="/">3D Object Detection Hub</a>
      </h1>
      <nav>
        <ul>
          <li><a href="/">Home</a></li>
          <li><a href="/datasets/">Datasets</a></li>
          <li><a href="/3d-object-detection/">Models</a></li>
          <li><a href="/references/">References</a></li>
          <li><a href="/about/">About</a></li>
        </ul>
      </nav>
    </div>
  </header>

  <main class="site-content">
    <h2 id="welcome-to-the-3d-object-detection-hub">Welcome to the <strong>3D Object Detection Hub</strong></h2>

<p>Your gateway to state-of-the-art 3D perception research. Here you’ll find:</p>

<h3 id="-datasets--benchmarks">📚 Datasets &amp; Benchmarks</h3>
<ul>
  <li><strong>KITTI</strong> (7,481 frames)</li>
  <li><strong>nuScenes</strong> (40k samples)</li>
  <li><strong>Waymo Open</strong> (1150 segments)</li>
</ul>

<h3 id="️-methods--models">🛠️ Methods &amp; Models</h3>
<ul>
  <li><strong>Mono3D</strong> – single-image 3D detection</li>
  <li><strong>SMOKE</strong> – sequential monocular detector</li>
  <li><strong>DD3D</strong> – distribution-driven approaches</li>
  <li><strong>MonoFlex</strong> – flexible monocular pipelines</li>
  <li><strong>Voxel Graph Network</strong> – <em>my thesis model</em> Test</li>
</ul>

<h3 id="explore">Explore</h3>
<ul>
  <li><a href="/models/">Models Database</a> ← click here to browse all the published 3D-OD models</li>
</ul>

<h3 id="-results--visuals">📈 Results &amp; Visuals</h3>
<ul>
  <li>Leaderboards, PR curves, AP tables</li>
  <li>Interactive demos &amp; point-cloud viewers</li>
</ul>

<blockquote>
  <p><strong>Thesis Highlight</strong><br />
In <em>“Multi-modal Voxel Graph Network for 3D Object Detection,”</em> I introduce a graph-based fusion of LiDAR voxels and RGB features via message-passing, achieving <strong>+5 % mAP</strong> on KITTI and strong generalization to nuScenes &amp; Waymo.</p>
</blockquote>

<h3 id="-getting-started">🚀 Getting Started</h3>
<ol>
  <li><strong>Clone the repo</strong><br />
```bash
git clone https://github.com/yourgithub/3d-object-detection-hub.git</li>
</ol>

  </main>

  <footer class="site-footer site-content">
    <p>&copy; 2025 3D Object Detection Hub</p>
  </footer>
</body>
</html>
